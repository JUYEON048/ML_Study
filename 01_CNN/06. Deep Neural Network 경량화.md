## 06. **Deep Neural Network 경량화**
</br>

> **비슷한 수준의 성능을 유지한 채 더 적은 파라미터 수와 연산량을 가지는 모델을 만드는 것을 의미.**

</br>

DNN 경량화 기술은 크게 **경량 알고리즘 연구**와 **알고리즘 경량화**로 나눠짐.

</br>

 - **경량 알고리즘 연구**
	  알고리즘 자체를 적은 연산과 효율적인 구조로 설계하여, 기존 모델 대비 효율을 극대화 시킴.
	 - **모델 구조 변경**(ResNet, DenseNet, SqueeseNet 등)
	 - **합성곱 필터 변경**(MobileNet, ShuffleNet 등)
	- **자동 모델 탐색**(NetAdapt, MnasNet 등)

	  
	  
- **알고리즘 경량화**
	 만들어진 모델의 파라미터들을 줄이는 모델 압축과 같은 기법 적용. 기존 기존 알고리즘의 불필요한 값 제거, 파라미터의 공통된 값 공유, 파라미터의 표현력을 잃지 않으며 기존 모델의 크기를 줄이는 연구 분야.
	- **모델 압축 기술**(Pruning, Quantization/Binarization, Weight Sharing)
	- **지식 증류 기술**
	- **하드웨어 가속화 기술**
	- **모델 압축을 적용한 경량 모델 자동 탐색 기술**

</br>
</br>
</br>

### 1. 다양한 Convolution
> **용어정리**
> W : input width
> H  : input Height
> C  : input channel
> K  : kernel(filter)의 크기(즉, filter는(K,K))
> M : output channel (filter개수)

</br>
</br>

### 1.1. Nomal Convolution
>![](http://media5.datahacker.rs/2018/11/06_04.png)
>(http://media5.datahacker.rs/2018/11/06_04.png)



>![](https://miro.medium.com/max/679/1*-KbwNtZYpJcUQs8yoRGgkQ.jpeg)</br>
>(https://miro.medium.com/max/679/1*-KbwNtZYpJcUQs8yoRGgkQ.jpeg)</br>



- **(파라미터 수)** 한 필터에 대해 input의 각 channel을 필터와 합성곱 해주기 때문에 필터 크기와 input의 channel 개수를 곱해주면 *CK^2*이 됨. output을 M개의 channel로 만들어주려면 이러한 filter의 개수가 총 M개 있어야하므로, *CK^2M*이 파라미터의 수가 됨.
- **(연산량)** 하나의 필터당 필요한 연산의 수를 알아내면 연산량이 구해짐, 연산량은 *CK^2MHW*.

 따라서 input의 크기뿐만 아니라 많은 요소들 (입력 채널의 수, 필터의 수, 커널의 크기)에 의해 연산량과 파라미터수가 증가하는 것을 알 수 있음.

</br>
</br>

### 1.2. Grouped Convolution
>![](https://blog.kakaocdn.net/dn/bnjEcA/btqw7PZ9hp6/GRL834Y9kSQoLOKDtsyUgK/img.png)</br>
>(https://blog.kakaocdn.net/dn/bnjEcA/btqw7PZ9hp6/GRL834Y9kSQoLOKDtsyUgK/img.png)</br>



>![](https://www.researchgate.net/profile/Gao-Huang/publication/321325862/figure/fig2/AS:667766038216712@1536219238662/The-transformations-within-a-layer-in-DenseNets-left-and-CondenseNets-at-training-time.png)</br>
>(https://www.researchgate.net/profile/Gao-Huang/publication/321325862/figure/fig2/AS:667766038216712@1536219238662/The-transformations-within-a-layer-in-DenseNets-left-and-CondenseNets-at-training-time.png)</br>



input channel을 여러 개의 그룹으로 나누어 각 그룹에 대해 독립적인 convolution을 수행하는 방식으로, 각 그룹의 입력 채널들 사이에 독립적인 필터를 학습.

- **(파라미터의 수)** *(K^2 x C x M) / group*
- **(연산량)** *(K^2 x C x M x H x W) / group*, 즉 normal conv의 1/g 연산량을 가짐.
- **(단점)** 그룹의 수는 Hyper parameter로, 그룹 수에 따라서 성능이 변함.

</br>
</br>

### 1.3. Depth-wise Convolution
>![Depth-wise Convolution](https://machinethink.net/images/mobilenets/RegularConvolution@2x.png)</br>
>(https://machinethink.net/images/mobilenets/RegularConvolution@2x.png)</br>

**채널마다 따로 필터를 학습하는 것**으로, 일반적인 convolution filter는 입력의 모든 채널의 영향을 받게 되어 완벽히 특정 채널만의 특징을 추출하는 것이 불가능함. 반면, Depth-wise convolution은 각 단일 채널에 대해서만 수행되는 필터들을 사용하므로, 필터 수는 입력 채널의 수와 동일하고, 결과적으로 입력 채널 수 만큼 그룹을 나눈 Grouped Convolution과 같음.

- **(파라미터수)** 각 input channel을 C개의 그룹으로 나누기 때문에 각 그룹당 channel의 수는 C/C=1가 되며, filter의 수는 input channel의 수와 같기 때문에 C개가 됨. 따라서 파라미터수는 *K^2 x C*.
- **(연산량)**  *K^2 x C x H x W*

</br>
</br>

### 1.4. Point-wise Convolution (1x1 convolution)
> ![](https://paperswithcode.com/media/methods/1_37sVdBZZ9VK50pcAklh8AQ_KE6C7Yb.png) </br>
> (https://paperswithcode.com/media/methods/1_37sVdBZZ9VK50pcAklh8AQ_KE6C7Yb.png) </br>

 Point-wise convolution은 커널 크기(filter크기)가 1x1로 고정된 convolution layer를 말한다. 각 채널에 대한 연산만 수행하며, output의 크기는 변하지 않고, channel의 수는 자유롭게 조절 할 수 있다. 하나의 필터는 가 입력 채널별로 하닁 가중치만 가지며, 이 가중치는 해달 채널의 모든 영역에 동일하게 적용된다. 즉, 입력 채널들에 대한 Linear Combination과 같다. **보통 Dimensional reduction(channel의 수를 줄이는 것)을 위해 많이 쓰이며, 연산량을 많이 줄일 수 있어 중요한 역할을 한다.**

- **(파라미터의 수)** standard convolution(normal convolution)에서 K=1인 경우와 같음. 따라서 총 파라미터 수는 *CM*.
- **(연산량)** K=1dls ruddndlrlEoansdp *CMHW*

</br>
</br>


### 1.5. Depth-wise Seperable convolution
>![](https://www.mdpi.com/sensors/sensors-21-00832/article_deploy/html/images/sensors-21-00832-g001-550.jpg) </br>
>(https://www.mdpi.com/sensors/sensors-21-00832/article_deploy/html/images/sensors-21-00832-g001-550.jpg)</br>

Depth-wise Seperable convolution은 **Depth-wise convolution**과 **Point-wise convolution**을 조합하여 사용하는 방식이다.  이 방식은 Xception에서 제안한 방법으로, 기존의 Convolutiond에서 전체의 channel 방향과 spatial 한 방향 모두를 한번에 고려했다면, 이 방식은 channel 방향과 spatial 방향을 분리하겠다는 아이디어이다. 이렇게 두 방법으로 분리를 하게 되어도 channel과 spatial한 방향 모두 보기 대문에, 기존의 convolution과 유사하게 동작하지만 파라미터의 수와 연산량은 훨씬 적다. 즉, 각 channel별 spatial convolution을 한 이후에 feature별 linear combination을 해주는 것이라고 보면된다.

- **(파라미터의 수)** Depth-wise convolution 후에 point-wise convolution을 수행하는 방식으로, 두 방식의 파라미터를 더해주기만 하면 된다. 따라서 *(K^2 x C) + CM = C(K^2 + M)*
- **(연산량)** 연산량 역시 두방식을 더해주면 된다. 따라서 *(K^2 x CHW) + CMHW = CHW(K^2 + M)*



</br>
</br>
</br>

>Deep Neural Network 경량화 참고자료 </br>
>https://sotudy.tistory.com/12 </br>
>https://sotudy.tistory.com/10 </br>

