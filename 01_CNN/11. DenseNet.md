## 11.DenseNet (Densely Connected Convolutional Network)

> **DenseNet Paper** </br>
>  https://ieeexplore.ieee.org/document/8099726</br>
</br>
</br>

### 1. Introduction
>![Residual block](https://neurohive.io/wp-content/uploads/2019/01/resnet-e1548261477164.png)</br>
>(https://neurohive.io/wp-content/uploads/2019/01/resnet-e1548261477164.png)</br>
</br>
 CNN Layer의 깊이가 깊어지면서, input 값에대한 기울기 정보가 소실되는 문제가 있었다. 이러한 문제를 해결하고자 ResNet, Highway Networks, GoogleNet 등 identity connection을 통해 신호(특성)을 우회하는 것을 시도하였다. 본 논문에는 이러한 connection에서 영감을 받았는데, layer간 정보 흐름을 최대화하기 위하여 모든 layer들이 서로 연결되게끔 구성하였다. 
 </br>

 >![ResNet Vs DenseNet](https://raw.githubusercontent.com/q0115643/my_blog/master/assets/images/paper-summary/Huang-CVPR2017/3.png)</br>
 >(https://raw.githubusercontent.com/q0115643/my_blog/master/assets/images/paper-summary/Huang-CVPR2017/3.png)</br>
 </br>
 각각의 layer는 이전 layer 1개뿐만 아니라, **이전의 모든 layer들로부터 추가적인 정보를 얻고, 그들 고유의 feature map을 그다음의 모든 layer로 전달** 한다. 이때, ResNet과는 달리 Feature들을 Summation하지 않고, 이들을 **Concatenating** 하여 n번째 layer가 이전의 모든 convolution block들의 feature map들로 구성된 n개의 input을 갖게끔 하였다. 이렇게 dense하게 연결되어있다는 이유로 이 구조를 DenseNet이라고 부른다.
</br>
 DenseNet은 기존 Convolution network에 비하여 Feature map에 대한 불필요한 학습이 필요가 없는데, 이는 이전의 모든 layer로부터 정보를 받아 Feature map이 더욱 더 견고해지기 때문이다. 따라서 **더 적은 파라미터 수** 를 요구한다. 
</br>
</br>
</br>

### 2. Dense Connectivity
>![DenseNet](https://pytorch.org/assets/images/densenet1.png)</br>
>(https://pytorch.org/assets/images/densenet1.png)</br>
</br>

 **ResNet** 의 경우 identity function과 n번째 layer의 비선형 변환(ReLU, Pooling, Conv로 구성된 composite function)의 출력이 **Summation** 으로 합해지기에 **네트워크의 정보 흐름을 방해** 할 수도 있다. 따라서, **DenseNet** 은 정보 흐름의 방해를 개선하기위하여 또 다른 connectivity pattern을 선보였다. 바로 **모든 layer가 모든 후속 layer로 연결되도록하는 direct connection** 을 가지며, 결과적으로 n번째 layer는 모든 이전 layer의 feature map을 입력으로 받는 것이다. 이를 Dense connectivity라고하며, 이 모델을 DenNet이라 부른다.
 
</br>
</br>
</br>

### 3. Composite function and Transition Layer
>![Composite function](https://i.imgur.com/O8ntGzS.png)</br>
>(https://i.imgur.com/O8ntGzS.png)</br>
</br>

 **(Composite function)** DenseNEt은 ResNet의 구조에 대해 분석한 "Identity mappings in deep residual networks, 2016 ECCV"논문에서 시험을 통해 제안한 **BathchNorm-ReLU-Conv**  순서의 pre-activation 구조를 사용한다. 
 </br>
 
  **(Transition Layer)** concatenation 연산은 feature map의 크기가 달라질 경우 사용이 불가능하다. 따라서 down-sampling layer를 이용하여 feature map의 크기를 바꾼다. 마지막 Dense Block을 제외한 나머지 Dense Block 뒤에 연결되어있으며, **BatchNorm-ReLU-1x1 Conv-2x2 Average pooling** 으로 구성된다.
</br>
</br>
</br>

### 4. Growth rate
>![Growth rate](https://hoya012.github.io/assets/img/densenet/1_comment.png)</br>
>(https://hoya012.github.io/assets/img/densenet/1_comment.png)</br>
</br>

 n번째 layer는 *Ko + k(n-1)* 개의 input feature map을 가지는데, 여기서 *Ko* 는 input layer의 채널 수 이다. DenseNet과 다른 네트워크(구조)의 중요한 차이점은 **very narrow layer** 를 가질 수 있다는 것인데, 여기서 **k는 하이퍼 파라미터** 로 네트워크의 growth rate를 위미한다. 
</br> 



 growth rate는 전역 상태에 각 layer가 기여하는 새로운 정보의 양을 조절한다. 이는, 각 feature map간 densely하게 연결되어 있는 구조에서 자칫 feature map의 channel 개수가 많은 경우 계속해서 hannel-wise로 concatenation이 되며 channel 많이지는 것을 막을 수 있다(기본적으로 DensNet에서 각 채널 개수는 굉장히 적으며, 상대적으로 적은 k값으로도 충분히 좋은 결과를 얻을 수 있다는것을 확인했다고한다).
</br>
</br>
</br>

### 5. Bottleneck layers
>![Bottleneck layers](https://hoya012.github.io/assets/img/densenet/2_new.PNG)</br>
>(https://hoya012.github.io/assets/img/densenet/2_new.PNG)</br>
</br>

  ResNet과 Inception등에서 사용되는 Bottleneck layer는 DenseNet에서도 적용이 되었다.
 > **Bottleneck layer** </br>
 >  Dimension reduction을 한 뒤 모든 연산을하고 다시 Filter의 갯수를 늘려 고차원으로 늘리는 방법.
</br>

3x3 convolution전에 1x1 convolution을 거쳐서 입력 feature map의 channel 개수를 줄이는 것까지는 같으나, 그 뒤 다시 입력 feature map의 channel 개수 만큼을 생성하는 대신 *growth rate* 만큼의 feature map을 생성하는 것이 차이 점이며 이를 통해 computational cost를 줄일 수 있다고 한다.
</br>

 또한, DensNet의 Bottleneck layer는 1x1 convolution 연산을 통해 4 x growth rate 개의 feature map을 만들고 그 뒤에 3x3 convolution을 통해 growth rate개의 feature map으로 줄여준다. (4 x growth rate의 4배라는 수치는 hyper-parameter이고 이에대한 자세한 설명은 논문에서 하지 않았다.)
</br>
</br>
</br>

### 6. Compression
</br>

 Transition layer를 통해 feature map의 수를 줄일 수 있다고 설명하였는데, 만약 Dense Block이 m개의 feature map을 가지는 경우 transition layer는 *θm* 개의 feature map으로 줄여 준다. 이때 *θ* 는 *0<θ≤1* 로, 이 를  **compression factor** 라고 한다. 만약 *θ =1*이면, feature map의 수는 바뀌지 않는다. *θ<1* 이 적용된 DenseNet을 **DenseNet-C** 라 하고, 실험에서는 *θ=0.5* 를 사용했다. 이때 bottleneck 및  *θ<1* 을 모두 적용한 모델을 **DenseNet-BC** 라 부른다.
 </br>
 
  만약 Growth rate가 4이고, 첫번째 Dense Bolck의 output channel 수가 16일 경우, 16 channel을 4개의 channel로 압축하여 각각의 모든 layer들에게 concatenation을 수행하게 되는데(Growth rate가 4이기 때문에), 이때 16 channel을 4 channel로 compresse하는 과정을 본 챕터에세 설명하는 compression 과과정고, compression rate를 compression factor라고 칭한다고 이해함.
 (나의 주관적인 이해, 논문에서는 해당부분에 대한 자세한 설명이 없음)
</br>
</br>
</br>

### 7. Implementation Details 
  >![DenseNet Architecture(for ImageNet)](https://blog.kakaocdn.net/dn/AtHF4/btqTDJQ8zXy/Ke2ZENI56T437FGAnkXmmK/img.png)</br>
  >(https://blog.kakaocdn.net/dn/AtHF4/btqTDJQ8zXy/Ke2ZENI56T437FGAnkXmmK/img.png)</br>
</br>
 ImageNet을 제외한 나머지 데이터셋 실험에서 사용한 DenseNet은 모두 같은 layer 수로 구성된 3개의 dense block을 가진다.(ImageNet에서는 DenseNet-BC 사용, 4개의 Densevlock)
</br>
첫 번째 dense block에 들어가기 전에 16개의 feature map을 출력하는 convolution이 수행되며, 이때 커널 사이즈는 3 x 3이다. 여기서 feature map의 사이즈를 고정시키기 위해 1 pixel 크기의 zero padding을 수행한다. 
</br>
추가로 dense block 사이에 1 x 1 conv → 2 x 2 average pooling layer로 구성되는 transition layer가 있으며, 끝단에는 GAP 및 softmax layer가 위치한다. 
</br>
3개의 dense block의 사이즈는 각각 32 x 32, 16 x 16, 8 x 8이며, basic DeseNet과 DenseNet-BC는 각각 다음 configuration을 사용하였다. 
</br>

> basic DenseNet</br>
> {L = 40, k = 12}</br>
> {L = 100, k = 12}</br>
> {L = 100, k = 24}</br>

</br>

> DenseNet-BC</br>
> {L = 100, k = 12}</br>
> {L = 250, k = 24}</br>
> {L = 190, k = 40}</br>
</br>
</br>
</br>

### 8. Experiments
>![Result based on CIRAT, SVHN](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fdaqkwb%2FbtqTyAHrcdT%2FUbhHZMFjvRaaNPfjU33K7k%2Fimg.png)</br>
>(https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fdaqkwb%2FbtqTyAHrcdT%2FUbhHZMFjvRaaNPfjU33K7k%2Fimg.png)</br>
</br>
 CIFAR와 SVHN에 대해서는 Accuracy, Capacity, Parameter Efficiency, Overfitting 관점에서 모두 좋은 성능을 보였다.
</br>
ImageNet에 대해서는 비슷한 성능을 보였지만, 파라미터 수가 현저히 적었다고 한다.

>![Error rate and parameters based ImageNet](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FuL2iJ%2FbtqTvQRMxst%2FBiWqa0wiKU1DpmgEfC0vQK%2Fimg.png) </br>
>(https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FuL2iJ%2FbtqTvQRMxst%2FBiWqa0wiKU1DpmgEfC0vQK%2Fimg.png)</br> 



</br>
</br>
</br>

### 9. Discussion and Conclusion
</br>
 DenseNet과 ResNet은 서로 매우 유사하지만, DenseNet의 경우 입력을 concatenation 한다는 점에서 달랐다. 따라서 모든 DenseNet layer에서 학습된 feature map을 모든 후속 layer에 연결할 수 있었다.
</br>

다양한 모델 중, **DenseNet-BC** 가 가장 좋은 성능을 보였으며, 이 모델이 ResNet과 비슷한 성능을 내는 데까지 필요한 파라미터는 겨우 1/3에 불과하였다고 한다.
</br>
결과적으로, DenseNet은 degradation이나 overfitting 없이 정확도를 꾸준히 개선할 수 있었으며, 상당히 적은 수의 파라미터 및 연산량으로도 최고 수준의 성능을 낼 수 있었다.


</br>
</br>
</br>

> **참고자료** </br>
> https://phil-baek.tistory.com/m/entry/DenseNet-Densely-Connected-Convolutional-Networks </br>
> https://hoya012.github.io/blog/DenseNet-Tutorial-1/ </br>
> https://yunmap.tistory.com/m/entry/%EC%A0%84%EC%82%B0%ED%95%99%ED%8A%B9%EA%B0%95-CS231n-1X1-Convolution-%EC%9D%B4%EB%9E%80 </br>




