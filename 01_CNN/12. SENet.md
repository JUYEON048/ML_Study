## 12. SENet(Squeeze-and-Excitation Networks)

> **SENet Paper** </br>
> https://arxiv.org/abs/1709.01507</br>

</br>
</br>

### 1. Introduction

</br>

- SENet은 2017년 이미지넷 대회에서 우승을 차지한 모델(논문은 2018년 CVPR에서 발표).
- top-5 error가 2.251% 로, 사람의 top-5 error(5%)보다 높은 결과. 이미지넷 데이터셋에서만큼은 사람보다 이미지 분류를 잘해낸다는 것을 의미.
- SENet 논문은 기존 어떤 모델에도 적용될 수 있는 SE block이라는 것을 제안함.
  VGGNet ,GoogleNet, ResNet등에 SE block을 첨가함으로써 성능 향상을 도모한 것.
- 성능은 향상되는 반면, hyperparameter는 많이 늘지 않아 연산량 증가는 크지 않음.

</br>
</br>

</br>

### 2. Squeeze-and-Excitation Blocks(SE Blocks)

![](https://t1.daumcdn.net/cfile/tistory/9925C94C5B7182A72F)



- **Squeeze: Global Information Embedding**

    X, U는 Feature map, Ftr은 컨볼루션으로 보면된다. H'xW'xC' 크기의 특성맵 X가 Ftr 컨볼루션을 통해 HxWxC 크기의 특성맵 U가 된다.
   그 다음에 **스퀴즈(squeeze)**를 실행하는데 **C개 채널의 2차원(HxW)의 특성맵들을 1x1 사이즈의 특성맵으로 변환**해주는 것이다. 간단히 global average pooling (GAP)을 통해 각 2차원의 특성맵을 평균내어 하나의 값을 얻는다. 논문의 저자들은 간단한 방식으로 정보 압축을 위하여 GAP를 사용했지만, 다른 방법론을 사용할 수 있다고 언급하였다.

  ![GAP](https://blog.kakaocdn.net/dn/cXcyTg/btqBD19YRvI/bDuCdnS1atbfJFlg27ej4K/img.png)

   이로인해 각 채널을 하나의 숫자로 묘사할 수 있다. 총 C개 채널의 특성맵이 있으므로 1x1xC의 특성맵으로 스퀴즈되는 것이다. 특성맵을 global하게 표현한 것이라고 볼 수 있는데, 컨볼루션이 local 정보를 다룬다면, 스퀴즈는 global 정보를 다룬다고 보는 것이다.

  

- **Excitation: Adaptive Recalibration**

   중요한 정보를 압축(Squeeze)한 후 재조정(Recalibration)을 진행하는데, 이 과정을 Excitation operation이라고 한다. 이 과정에서는 **채널 간 의존성(channel-wise dependencies)**을 계산하게 된다.  논문에서는 Fully connected layer와 비선형 함수를 조절하는 것으로 계산하였다.

  
  $$
  s=Fex(z,W)=σ(W2δ(W1z))
  $$
   

  σ는 시그모이드함수이고, δ는 ReLU 함수이다. 위 공식을 살펴보자면, 

  1) 먼저 스퀴즈를 통해 얻은 zc을 인풋으로 삼아서 W1 가중치들과 fully-connected하게 곱해준다. 

  2) 그래서 얻은 값을 δ, 즉 ReLU 함수로 활성화해준 후에 W2 가중치들과 fully-connected하게 곱해준다. 

  3) 그렇게 얻은 값을 σ, 즉 시그모이드 함수로 활성화해줘서 0과 1사이의 값을 갖게 한다. 

  4) 따라서 각 채널의 상대적 중요도를 0과 1의 값으로 파악할 수 있게 된다.

   

   여기서 기억해야할 것은 FC 층들이 **병목(bottle-neck) 구조**가 되게 만든다는 것이다. 은닉(hidden) 층의 뉴런의 갯수를 입력 층보다 작고,  출력 층의 뉴런의 갯수는 입력 층과 동일하다. 병목 구조로 해주는 이유는 **hyper-parameter의 갯수를 많이 늘리지 않기 위함**도 있고, **일반화에 도움**을 주기 위함도 있다. 
   은닉 층의 뉴런 갯수는 reduction ratio, r값에 의해 결정된다. r이 클수록 은닉 층의 뉴런 갯수가 더 적어지고, 복잡도도 더 낮아진다. 따라서 각 층의 뉴런의 갯수는 채널의 갯수인 C에서 시작해서 C/r로 감소했다가 다시 C로 증가한다. 

  ![](https://i.imgur.com/sMoKNuy.png)

  이렇게 얻은 C개의 sc를 uc에 각각 곱해줘서 U를 재보정해줍니다. 그것을 X~라고 한다. 

  ![](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fm7Kw8%2FbtqBDbkWqNn%2FhpWZ4JzKpGHDZfaKGCv1Ak%2Fimg.png)

   정리하면, Feature map은 x에서 컨볼루션을 통해 U로, U에서 SE block을 통해 X~로 변환된다.
   **SE block의 목적은 한마디로 컨볼루션을 통해 생성된 특성을 채널당 중요도를 고려해서 재보정(recalibration)하는 것으로,** 이러한 SE block을 컨볼루션 연산 뒤에 붙여줌으로써 성능 향상을 도모한 것이 바로 SENet의 핵심이다.

</br>
</br>

</br>

### 3. 기존 CNN 모델과 결합

 SE block은 기존의 CNN 모델들에 붙여서 사용할 수 있다. VGGNet의 경우에는 컨볼루션 및 활성화 뒤에 바로 붙이면 되고, GoogLeNet의 경우에는 Inception 모듈 뒤에 붙이면 되고, ResNet의 경우에는 Residual 모듈 뒤에 붙이면 된다.

![](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FpZvP2%2FbtqBEAqMq44%2FfQLZXp6PKydP0k1AoSfLG0%2Fimg.png)

</br>
</br>

</br>

### 4. 성능 분석

![](https://sike6054.github.io/blog/images/SENet,%20Table.1(removed).png)

[**TABLE 1**. (Left) ResNet-50 [13]. (Middle) SE-ResNet-50. (Right) SE-ResNeXt-50 with a 32×4d template. The shapes and operations with specific parameter settings of a residual building block are listed inside the brackets and the number of stacked blocks in a stage is presented outside. The inner brackets following by fc indicates the output dimension of the two fully connected layers in an SE module.]

![](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2F3Alc6%2FbtqBD1Wsbqo%2Flnt5lk9Zm3Qlsi0MTlGfy0%2Fimg.png)

[**TABLE 2**. Single-crop error rates (%) on the ImageNet validation set and complexity comparisons. The original column refers to the results reported in the original papers (the results of ResNets are obtained from the website: https://github.com/Kaiminghe/deep-residual-networks). *To enable a fair comparison, we re-train the baseline models and report the scores in the re-implementation column. The SENet column refers to the corresponding architectures in which SE blocks have been added.* The numbers in brackets denote the performance improvement over the re-implemented baselines. † indicates that the model has been evaluated on the non-blacklisted subset of the validation set (this is discussed in more detail in [21]), which may slightly improve results. VGG-16 and SE-VGG-16 are trained with batch normalization.]

</br>

![](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbBj2o6%2FbtqBBVpz8dP%2FnVKOubtdLGyNOpT7YsoNmk%2Fimg.png)

 As part of this submission, we constructed an additional model, SENet-154, by integrating SE blocks with a modified ResNeXt [19] (the details of the architecture are provided in Appendix).

</br>
</br>
</br>

> **참고자료** </br>
> https://bskyvision.com/640</br>
> [https://jayhey.github.io/deep%20learning/2018/07/18/SENet/](https://jayhey.github.io/deep learning/2018/07/18/SENet/) </br>

